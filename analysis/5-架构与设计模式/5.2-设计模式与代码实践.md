# 5.2 设计模式与代码实践

[返回上级](../5-架构与设计模式.md) | [English Version](../5-architecture-and-design-patterns/5.2-design-patterns-and-code-practice.md)

## 目录

- [5.2 设计模式与代码实践](#52-设计模式与代码实践)
  - [目录](#目录)
  - [5.2.1 设计模式理论基础](#521-设计模式理论基础)
    - [5.2.1.1 设计模式的形式化定义](#5211-设计模式的形式化定义)
    - [5.2.1.2 模式分类体系](#5212-模式分类体系)
    - [5.2.1.3 模式选择的形式化准则](#5213-模式选择的形式化准则)
  - [5.2.2 经典GoF模式实践](#522-经典gof模式实践)
    - [5.2.2.1 创建型模式的现代实现](#5221-创建型模式的现代实现)
    - [5.2.2.2 结构型模式的高级应用](#5222-结构型模式的高级应用)
  - [5.2.3 并发与并行模式](#523-并发与并行模式)
    - [5.2.3.1 Actor模型实现](#5231-actor模型实现)
    - [5.2.3.2 生产者-消费者模式](#5232-生产者-消费者模式)
    - [5.2.3.3 工作窃取模式](#5233-工作窃取模式)
  - [5.2.4 分布式系统模式](#524-分布式系统模式)
    - [5.2.4.1 熔断器模式](#5241-熔断器模式)
  - [5.2.5 现代架构模式](#525-现代架构模式)
    - [5.2.5.1 事件溯源模式](#5251-事件溯源模式)
    - [5.2.5.2 CQRS模式](#5252-cqrs模式)
  - [5.2.6 形式化验证与模式](#526-形式化验证与模式)
    - [5.2.6.1 模式的不变量验证](#5261-模式的不变量验证)
    - [5.2.6.2 并发模式的安全性验证](#5262-并发模式的安全性验证)
  - [5.2.7 性能优化模式](#527-性能优化模式)
    - [5.2.7.1 缓存模式的性能分析](#5271-缓存模式的性能分析)
    - [5.2.7.2 对象池模式](#5272-对象池模式)
  - [5.2.8 工程实践案例](#528-工程实践案例)
    - [5.2.8.1 微服务架构的模式组合](#5281-微服务架构的模式组合)
    - [5.2.8.2 高性能计算的模式应用](#5282-高性能计算的模式应用)
  - [5.2.9 参考文献与延伸阅读](#529-参考文献与延伸阅读)
    - [5.2.9.1 经典文献](#5291-经典文献)
    - [5.2.9.2 现代架构模式](#5292-现代架构模式)
    - [5.2.9.3 形式化方法与模式](#5293-形式化方法与模式)
    - [5.2.9.4 并发与分布式模式](#5294-并发与分布式模式)
    - [5.2.9.5 在线资源](#5295-在线资源)
    - [5.2.9.6 开源实现参考](#5296-开源实现参考)

---

## 5.2.1 设计模式理论基础

### 5.2.1.1 设计模式的形式化定义

设计模式是在特定上下文中反复出现的问题的通用解决方案，可以用形式化方法进行精确描述。

**定义 5.2.1** (设计模式): 设计模式 $P$ 可形式化为四元组：
$$P = \langle C, Pr, S, Co \rangle$$

其中：

- $C$ 是上下文(Context)，描述模式适用的环境
- $Pr$ 是问题(Problem)，描述需要解决的设计问题
- $S$ 是解决方案(Solution)，描述模式的结构和行为
- $Co$ 是后果(Consequences)，描述应用模式的结果

### 5.2.1.2 模式分类体系

```mermaid
graph TD
    A[设计模式] --> B[经典GoF模式]
    A --> C[并发模式]
    A --> D[分布式模式]
    A --> E[架构模式]
    
    B --> B1[创建型]
    B --> B2[结构型]
    B --> B3[行为型]
    
    C --> C1[同步模式]
    C --> C2[异步模式]
    C --> C3[并行计算]
    
    D --> D1[通信模式]
    D --> D2[一致性模式]
    D --> D3[容错模式]
    
    E --> E1[微服务]
    E --> E2[事件驱动]
    E --> E3[响应式]
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#bbf,stroke:#333,stroke-width:2px
    style C fill:#bfb,stroke:#333,stroke-width:2px
    style D fill:#fbf,stroke:#333,stroke-width:2px
```

### 5.2.1.3 模式选择的形式化准则

```lean
-- 模式选择的Lean建模
-- 模式属性定义
structure PatternProperty :=
  (reusability : ℝ)     -- 可重用性
  (flexibility : ℝ)     -- 灵活性  
  (complexity : ℝ)      -- 复杂度
  (performance : ℝ)     -- 性能影响

-- 问题上下文
structure ProblemContext :=
  (scale : ℕ)           -- 系统规模
  (concurrency_level : ℕ) -- 并发程度
  (distribution : Bool)   -- 是否分布式
  (performance_critical : Bool) -- 是否性能敏感

-- 模式适用性判断
def pattern_suitable (pattern : PatternProperty) (context : ProblemContext) : Bool :=
  pattern.reusability ≥ 0.7 ∧ 
  (context.performance_critical → pattern.performance ≥ 0.8) ∧
  (context.scale > 1000 → pattern.flexibility ≥ 0.8)

-- 最优模式选择定理
theorem optimal_pattern_selection 
  (patterns : List PatternProperty) 
  (context : ProblemContext) :
  ∃ p ∈ patterns, pattern_suitable p context ∧ 
  ∀ q ∈ patterns, pattern_suitable q context → 
  p.reusability * p.flexibility / p.complexity ≥ 
  q.reusability * q.flexibility / q.complexity :=
  sorry
```

## 5.2.2 经典GoF模式实践

### 5.2.2.1 创建型模式的现代实现

**单例模式的线程安全实现**:

```rust
use std::sync::{Arc, Mutex, Once};
use once_cell::sync::Lazy;

// 传统单例模式（线程安全）
pub struct Logger {
    level: String,
    output: String,
}

impl Logger {
    fn new() -> Self {
        Logger {
            level: "INFO".to_string(),
            output: "stdout".to_string(),
        }
    }
    
    pub fn instance() -> &'static Mutex<Logger> {
        static mut LOGGER: Option<Mutex<Logger>> = None;
        static INIT: Once = Once::new();
        
        unsafe {
            INIT.call_once(|| {
                LOGGER = Some(Mutex::new(Logger::new()));
            });
            LOGGER.as_ref().unwrap()
        }
    }
    
    pub fn log(&self, message: &str) {
        println!("[{}] {}", self.level, message);
    }
}

// 现代化单例模式（推荐）
static GLOBAL_LOGGER: Lazy<Arc<Mutex<Logger>>> = Lazy::new(|| {
    Arc::new(Mutex::new(Logger::new()))
});

// 工厂模式的泛型实现
pub trait Product: Send + Sync {
    fn create() -> Self where Self: Sized;
    fn operation(&self) -> String;
}

pub trait Factory<T: Product> {
    fn create_product(&self) -> Box<T>;
}

// 具体产品实现
pub struct DatabaseConnection {
    connection_string: String,
}

impl Product for DatabaseConnection {
    fn create() -> Self {
        DatabaseConnection {
            connection_string: "postgresql://localhost:5432/db".to_string(),
        }
    }
    
    fn operation(&self) -> String {
        format!("Connected to: {}", self.connection_string)
    }
}

pub struct DatabaseFactory;

impl Factory<DatabaseConnection> for DatabaseFactory {
    fn create_product(&self) -> Box<DatabaseConnection> {
        Box::new(DatabaseConnection::create())
    }
}

// 建造者模式的流式API
#[derive(Debug, Default)]
pub struct HttpClient {
    base_url: Option<String>,
    timeout: Option<u64>,
    headers: Vec<(String, String)>,
    retry_count: u32,
}

impl HttpClient {
    pub fn builder() -> HttpClientBuilder {
        HttpClientBuilder::default()
    }
    
    pub async fn get(&self, path: &str) -> Result<String, Box<dyn std::error::Error>> {
        // 实际HTTP请求实现
        Ok(format!("GET {}/{}", self.base_url.as_ref().unwrap_or(&"".to_string()), path))
    }
}

#[derive(Default)]
pub struct HttpClientBuilder {
    client: HttpClient,
}

impl HttpClientBuilder {
    pub fn base_url(mut self, url: &str) -> Self {
        self.client.base_url = Some(url.to_string());
        self
    }
    
    pub fn timeout(mut self, seconds: u64) -> Self {
        self.client.timeout = Some(seconds);
        self
    }
    
    pub fn header(mut self, key: &str, value: &str) -> Self {
        self.client.headers.push((key.to_string(), value.to_string()));
        self
    }
    
    pub fn retry_count(mut self, count: u32) -> Self {
        self.client.retry_count = count;
        self
    }
    
    pub fn build(self) -> Result<HttpClient, &'static str> {
        if self.client.base_url.is_none() {
            return Err("Base URL is required");
        }
        Ok(self.client)
    }
}
```

### 5.2.2.2 结构型模式的高级应用

**适配器模式与类型系统集成**:

```haskell
-- Haskell中的适配器模式
{-# LANGUAGE GADTs #-}
{-# LANGUAGE TypeFamilies #-}
module AdapterPattern where

-- 旧接口
class LegacyInterface a where
  legacyOperation :: a -> String

-- 新接口
class ModernInterface a where
  modernOperation :: a -> IO String

-- 适配器类型类
class Adaptable old new where
  adapt :: old -> new

-- 具体实现
data LegacyService = LegacyService { legacyData :: String }
data ModernService = ModernService { modernData :: String }

instance LegacyInterface LegacyService where
  legacyOperation (LegacyService d) = "Legacy: " ++ d

instance ModernInterface ModernService where
  modernOperation (ModernService d) = return $ "Modern: " ++ d

-- 适配器实现
instance Adaptable LegacyService ModernService where
  adapt (LegacyService d) = ModernService ("Adapted: " ++ d)

-- 使用示例
useAdapter :: LegacyService -> IO String
useAdapter legacy = modernOperation (adapt legacy)
```

**装饰器模式的函数式实现**:

```rust
use std::future::Future;
use std::pin::Pin;
use std::time::Instant;

// 基础服务trait
#[async_trait::async_trait]
pub trait Service {
    type Request;
    type Response;
    
    async fn call(&self, req: Self::Request) -> Result<Self::Response, Box<dyn std::error::Error>>;
}

// 装饰器trait
#[async_trait::async_trait]
pub trait ServiceDecorator<S: Service>: Service {
    fn inner(&self) -> &S;
}

// 日志装饰器
pub struct LoggingDecorator<S> {
    inner: S,
    logger_name: String,
}

impl<S> LoggingDecorator<S> {
    pub fn new(service: S, logger_name: String) -> Self {
        Self { inner: service, logger_name }
    }
}

#[async_trait::async_trait]
impl<S: Service + Send + Sync> Service for LoggingDecorator<S>
where
    S::Request: Send + Sync + std::fmt::Debug,
    S::Response: Send + Sync + std::fmt::Debug,
{
    type Request = S::Request;
    type Response = S::Response;
    
    async fn call(&self, req: Self::Request) -> Result<Self::Response, Box<dyn std::error::Error>> {
        println!("[{}] Request: {:?}", self.logger_name, req);
        let start = Instant::now();
        
        let result = self.inner.call(req).await;
        
        let duration = start.elapsed();
        match &result {
            Ok(resp) => println!("[{}] Response: {:?} (took {:?})", self.logger_name, resp, duration),
            Err(err) => println!("[{}] Error: {:?} (took {:?})", self.logger_name, err, duration),
        }
        
        result
    }
}

// 重试装饰器
pub struct RetryDecorator<S> {
    inner: S,
    max_retries: u32,
}

impl<S> RetryDecorator<S> {
    pub fn new(service: S, max_retries: u32) -> Self {
        Self { inner: service, max_retries }
    }
}

#[async_trait::async_trait]
impl<S: Service + Send + Sync> Service for RetryDecorator<S>
where
    S::Request: Send + Sync + Clone,
    S::Response: Send + Sync,
{
    type Request = S::Request;
    type Response = S::Response;
    
    async fn call(&self, req: Self::Request) -> Result<Self::Response, Box<dyn std::error::Error>> {
        let mut last_error = None;
        
        for attempt in 0..=self.max_retries {
            match self.inner.call(req.clone()).await {
                Ok(resp) => return Ok(resp),
                Err(err) => {
                    last_error = Some(err);
                    if attempt < self.max_retries {
                        tokio::time::sleep(tokio::time::Duration::from_millis(100 * (attempt + 1) as u64)).await;
                    }
                }
            }
        }
        
        Err(last_error.unwrap())
    }
}

// 组合装饰器的示例
pub fn create_decorated_service<S: Service + Send + Sync + 'static>(
    service: S
) -> impl Service<Request = S::Request, Response = S::Response>
where
    S::Request: Send + Sync + Clone + std::fmt::Debug,
    S::Response: Send + Sync + std::fmt::Debug,
{
    RetryDecorator::new(
        LoggingDecorator::new(service, "MyService".to_string()),
        3
    )
}
```

---

[返回目录](../0-总览与导航/0.1-全局主题树形目录.md)

## 5.2.3 并发与并行模式

### 5.2.3.1 Actor模型实现

Actor模型通过消息传递实现并发，每个Actor维护自己的状态，避免共享可变状态。

```rust
use tokio::sync::{mpsc, oneshot};
use std::collections::HashMap;
use std::time::Duration;

// Actor消息定义
#[derive(Debug)]
pub enum ActorMessage<T> {
    Request { 
        data: T, 
        reply_to: oneshot::Sender<T> 
    },
    Shutdown,
}

// Actor状态
#[async_trait::async_trait]
pub trait ActorState: Send {
    type Message: Send;
    type Error: Send;
    
    async fn handle_message(&mut self, msg: Self::Message) -> Result<(), Self::Error>;
}

// Actor引用
#[derive(Clone)]
pub struct ActorRef<T> {
    sender: mpsc::Sender<ActorMessage<T>>,
}

impl<T: Send + 'static> ActorRef<T> {
    pub async fn send(&self, data: T) -> Result<T, Box<dyn std::error::Error>> {
        let (tx, rx) = oneshot::channel();
        
        self.sender.send(ActorMessage::Request { 
            data, 
            reply_to: tx 
        }).await?;
        
        Ok(rx.await?)
    }
    
    pub async fn shutdown(&self) -> Result<(), Box<dyn std::error::Error>> {
        self.sender.send(ActorMessage::Shutdown).await?;
        Ok(())
    }
}

// Actor系统
pub struct ActorSystem<T, S> 
where 
    T: Send + 'static,
    S: ActorState<Message = T> + 'static,
{
    state: S,
    receiver: mpsc::Receiver<ActorMessage<T>>,
}

impl<T, S> ActorSystem<T, S>
where
    T: Send + 'static,
    S: ActorState<Message = T> + 'static,
{
    pub fn spawn(state: S) -> ActorRef<T> {
        let (sender, receiver) = mpsc::channel(100);
        
        let mut actor = ActorSystem { state, receiver };
        
        tokio::spawn(async move {
            actor.run().await;
        });
        
        ActorRef { sender }
    }
    
    async fn run(&mut self) {
        while let Some(msg) = self.receiver.recv().await {
            match msg {
                ActorMessage::Request { data, reply_to } => {
                    // 处理消息
                    if let Err(e) = self.state.handle_message(data).await {
                        // 错误处理
                        eprintln!("Actor处理消息失败: {:?}", e);
                    }
                    // 注意：这里简化了回复逻辑
                },
                ActorMessage::Shutdown => {
                    break;
                }
            }
        }
    }
}

// 示例：计数器Actor
pub struct CounterActor {
    count: i64,
}

#[derive(Debug)]
pub enum CounterMessage {
    Increment,
    Decrement,
    GetCount,
}

#[async_trait::async_trait]
impl ActorState for CounterActor {
    type Message = CounterMessage;
    type Error = Box<dyn std::error::Error + Send>;
    
    async fn handle_message(&mut self, msg: Self::Message) -> Result<(), Self::Error> {
        match msg {
            CounterMessage::Increment => {
                self.count += 1;
                println!("Count incremented to: {}", self.count);
            },
            CounterMessage::Decrement => {
                self.count -= 1;
                println!("Count decremented to: {}", self.count);
            },
            CounterMessage::GetCount => {
                println!("Current count: {}", self.count);
            }
        }
        Ok(())
    }
}
```

### 5.2.3.2 生产者-消费者模式

```rust
use std::sync::{Arc, Condvar, Mutex};
use std::collections::VecDeque;
use std::thread;
use std::time::Duration;

// 有界缓冲区
pub struct BoundedBuffer<T> {
    buffer: Mutex<VecDeque<T>>,
    not_empty: Condvar,
    not_full: Condvar,
    capacity: usize,
}

impl<T> BoundedBuffer<T> {
    pub fn new(capacity: usize) -> Self {
        Self {
            buffer: Mutex::new(VecDeque::with_capacity(capacity)),
            not_empty: Condvar::new(),
            not_full: Condvar::new(),
            capacity,
        }
    }
    
    pub fn produce(&self, item: T) -> Result<(), &'static str> {
        let mut buffer = self.buffer.lock().unwrap();
        
        // 等待缓冲区有空间
        while buffer.len() >= self.capacity {
            buffer = self.not_full.wait(buffer).unwrap();
        }
        
        buffer.push_back(item);
        
        // 通知消费者
        self.not_empty.notify_one();
        
        Ok(())
    }
    
    pub fn consume(&self) -> Result<T, &'static str> {
        let mut buffer = self.buffer.lock().unwrap();
        
        // 等待缓冲区有数据
        while buffer.is_empty() {
            buffer = self.not_empty.wait(buffer).unwrap();
        }
        
        let item = buffer.pop_front().unwrap();
        
        // 通知生产者
        self.not_full.notify_one();
        
        Ok(item)
    }
}

// 异步版本的生产者-消费者
pub struct AsyncBoundedBuffer<T> {
    inner: Arc<tokio::sync::Mutex<VecDeque<T>>>,
    capacity: usize,
    not_empty: Arc<tokio::sync::Notify>,
    not_full: Arc<tokio::sync::Notify>,
}

impl<T> AsyncBoundedBuffer<T> {
    pub fn new(capacity: usize) -> Self {
        Self {
            inner: Arc::new(tokio::sync::Mutex::new(VecDeque::with_capacity(capacity))),
            capacity,
            not_empty: Arc::new(tokio::sync::Notify::new()),
            not_full: Arc::new(tokio::sync::Notify::new()),
        }
    }
    
    pub async fn produce(&self, item: T) -> Result<(), &'static str> {
        loop {
            {
                let mut buffer = self.inner.lock().await;
                if buffer.len() < self.capacity {
                    buffer.push_back(item);
                    self.not_empty.notify_one();
                    return Ok(());
                }
            }
            
            // 等待缓冲区有空间
            self.not_full.notified().await;
        }
    }
    
    pub async fn consume(&self) -> Result<T, &'static str> {
        loop {
            {
                let mut buffer = self.inner.lock().await;
                if let Some(item) = buffer.pop_front() {
                    self.not_full.notify_one();
                    return Ok(item);
                }
            }
            
            // 等待缓冲区有数据
            self.not_empty.notified().await;
        }
    }
}
```

### 5.2.3.3 工作窃取模式

```rust
use std::sync::{Arc, Mutex};
use std::collections::VecDeque;
use crossbeam::deque::{Injector, Stealer, Worker};
use std::thread;
use rayon::prelude::*;

// 工作窃取调度器
pub struct WorkStealingScheduler<T> {
    global_queue: Arc<Injector<T>>,
    workers: Vec<Worker<T>>,
    stealers: Vec<Stealer<T>>,
}

impl<T: Send + 'static> WorkStealingScheduler<T> {
    pub fn new(num_workers: usize) -> Self {
        let global_queue = Arc::new(Injector::new());
        let mut workers = Vec::with_capacity(num_workers);
        let mut stealers = Vec::with_capacity(num_workers);
        
        for _ in 0..num_workers {
            let worker = Worker::new_fifo();
            let stealer = worker.stealer();
            
            workers.push(worker);
            stealers.push(stealer);
        }
        
        Self {
            global_queue,
            workers,
            stealers,
        }
    }
    
    pub fn submit(&self, task: T) {
        self.global_queue.push(task);
    }
    
    pub fn run<F>(&self, mut task_processor: F) 
    where
        F: Fn(T) + Send + Sync + Clone + 'static,
    {
        let handles: Vec<_> = self.workers
            .iter()
            .enumerate()
            .map(|(worker_id, worker)| {
                let global_queue = self.global_queue.clone();
                let stealers = self.stealers.clone();
                let processor = task_processor.clone();
                
                thread::spawn(move || {
                    loop {
                        // 1. 先从本地队列获取任务
                        if let Some(task) = worker.pop() {
                            processor(task);
                            continue;
                        }
                        
                        // 2. 从全局队列获取任务
                        if let Some(task) = global_queue.steal().success() {
                            processor(task);
                            continue;
                        }
                        
                        // 3. 从其他工作线程窃取任务
                        let mut found_task = false;
                        for (i, stealer) in stealers.iter().enumerate() {
                            if i != worker_id {
                                if let Some(task) = stealer.steal().success() {
                                    processor(task);
                                    found_task = true;
                                    break;
                                }
                            }
                        }
                        
                        if !found_task {
                            // 没有任务，短暂休眠
                            thread::sleep(Duration::from_millis(1));
                        }
                    }
                })
            })
            .collect();
        
        // 等待所有工作线程完成
        for handle in handles {
            handle.join().unwrap();
        }
    }
}
```

## 5.2.4 分布式系统模式

### 5.2.4.1 熔断器模式

```rust
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use tokio::time::timeout;

// 熔断器状态
#[derive(Debug, Clone, PartialEq)]
pub enum CircuitState {
    Closed,    // 正常状态
    Open,      // 熔断状态
    HalfOpen,  // 半开状态
}

// 熔断器配置
#[derive(Debug, Clone)]
pub struct CircuitBreakerConfig {
    pub failure_threshold: usize,        // 失败阈值
    pub recovery_timeout: Duration,      // 恢复超时
    pub request_timeout: Duration,       // 请求超时
    pub success_threshold: usize,        // 成功阈值（半开状态）
}

impl Default for CircuitBreakerConfig {
    fn default() -> Self {
        Self {
            failure_threshold: 5,
            recovery_timeout: Duration::from_secs(60),
            request_timeout: Duration::from_secs(30),
            success_threshold: 3,
        }
    }
}

// 熔断器统计信息
#[derive(Debug, Default)]
struct CircuitStats {
    consecutive_failures: usize,
    consecutive_successes: usize,
    last_failure_time: Option<Instant>,
    total_requests: usize,
    total_failures: usize,
}

// 熔断器实现
pub struct CircuitBreaker {
    state: Arc<Mutex<CircuitState>>,
    stats: Arc<Mutex<CircuitStats>>,
    config: CircuitBreakerConfig,
}

impl CircuitBreaker {
    pub fn new(config: CircuitBreakerConfig) -> Self {
        Self {
            state: Arc::new(Mutex::new(CircuitState::Closed)),
            stats: Arc::new(Mutex::new(CircuitStats::default())),
            config,
        }
    }
    
    pub async fn call<F, T, E>(&self, operation: F) -> Result<T, CircuitBreakerError<E>>
    where
        F: std::future::Future<Output = Result<T, E>>,
    {
        // 检查当前状态
        if !self.can_execute()? {
            return Err(CircuitBreakerError::CircuitOpen);
        }
        
        // 执行操作
        let result = timeout(self.config.request_timeout, operation).await;
        
        match result {
            Ok(Ok(success)) => {
                self.on_success();
                Ok(success)
            },
            Ok(Err(error)) => {
                self.on_failure();
                Err(CircuitBreakerError::OperationFailed(error))
            },
            Err(_) => {
                self.on_failure();
                Err(CircuitBreakerError::Timeout)
            }
        }
    }
    
    fn can_execute(&self) -> Result<bool, CircuitBreakerError<()>> {
        let mut state = self.state.lock().unwrap();
        let stats = self.stats.lock().unwrap();
        
        match *state {
            CircuitState::Closed => Ok(true),
            CircuitState::Open => {
                // 检查是否可以尝试恢复
                if let Some(last_failure) = stats.last_failure_time {
                    if last_failure.elapsed() >= self.config.recovery_timeout {
                        *state = CircuitState::HalfOpen;
                        Ok(true)
                    } else {
                        Ok(false)
                    }
                } else {
                    Ok(false)
                }
            },
            CircuitState::HalfOpen => Ok(true),
        }
    }
    
    fn on_success(&self) {
        let mut state = self.state.lock().unwrap();
        let mut stats = self.stats.lock().unwrap();
        
        stats.consecutive_failures = 0;
        stats.consecutive_successes += 1;
        stats.total_requests += 1;
        
        match *state {
            CircuitState::HalfOpen => {
                if stats.consecutive_successes >= self.config.success_threshold {
                    *state = CircuitState::Closed;
                    stats.consecutive_successes = 0;
                }
            },
            _ => {}
        }
    }
    
    fn on_failure(&self) {
        let mut state = self.state.lock().unwrap();
        let mut stats = self.stats.lock().unwrap();
        
        stats.consecutive_failures += 1;
        stats.consecutive_successes = 0;
        stats.total_requests += 1;
        stats.total_failures += 1;
        stats.last_failure_time = Some(Instant::now());
        
        if stats.consecutive_failures >= self.config.failure_threshold {
            *state = CircuitState::Open;
        }
    }
    
    pub fn get_state(&self) -> CircuitState {
        self.state.lock().unwrap().clone()
    }
}

#[derive(Debug)]
pub enum CircuitBreakerError<E> {
    CircuitOpen,
    Timeout,
    OperationFailed(E),
}
```

## 5.2.5 现代架构模式

### 5.2.5.1 事件溯源模式

事件溯源通过存储状态变更事件而非当前状态来实现数据持久化。

```rust
use serde::{Serialize, Deserialize};
use std::collections::HashMap;
use uuid::Uuid;
use chrono::{DateTime, Utc};

// 事件trait
pub trait Event: Send + Sync + Clone + Serialize + for<'de> Deserialize<'de> {
    type EntityId: Clone + Eq + std::hash::Hash;
    
    fn entity_id(&self) -> Self::EntityId;
    fn event_type(&self) -> &'static str;
    fn timestamp(&self) -> DateTime<Utc>;
}

// 聚合根trait
pub trait AggregateRoot: Send + Sync + Clone {
    type Id: Clone + Eq + std::hash::Hash;
    type Event: Event<EntityId = Self::Id>;
    type Error;
    
    fn apply_event(&mut self, event: &Self::Event) -> Result<(), Self::Error>;
    fn get_id(&self) -> Self::Id;
}

// 事件存储trait
#[async_trait::async_trait]
pub trait EventStore<E: Event> {
    type Error;
    
    async fn append_events(&mut self, events: Vec<E>) -> Result<(), Self::Error>;
    async fn get_events(&self, entity_id: E::EntityId, from_version: Option<u64>) -> Result<Vec<E>, Self::Error>;
}

// 内存事件存储实现
pub struct InMemoryEventStore<E: Event> {
    events: HashMap<E::EntityId, Vec<E>>,
}

impl<E: Event> InMemoryEventStore<E> {
    pub fn new() -> Self {
        Self {
            events: HashMap::new(),
        }
    }
}

#[async_trait::async_trait]
impl<E: Event> EventStore<E> for InMemoryEventStore<E> {
    type Error = Box<dyn std::error::Error + Send + Sync>;
    
    async fn append_events(&mut self, events: Vec<E>) -> Result<(), Self::Error> {
        for event in events {
            let entity_id = event.entity_id();
            self.events.entry(entity_id).or_insert_with(Vec::new).push(event);
        }
        Ok(())
    }
    
    async fn get_events(&self, entity_id: E::EntityId, _from_version: Option<u64>) -> Result<Vec<E>, Self::Error> {
        Ok(self.events.get(&entity_id).cloned().unwrap_or_default())
    }
}

// 示例：银行账户聚合
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BankAccount {
    id: Uuid,
    balance: i64,
    is_active: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AccountEvent {
    AccountCreated {
        id: Uuid,
        initial_balance: i64,
        timestamp: DateTime<Utc>,
    },
    MoneyDeposited {
        id: Uuid,
        amount: i64,
        timestamp: DateTime<Utc>,
    },
    MoneyWithdrawn {
        id: Uuid,
        amount: i64,
        timestamp: DateTime<Utc>,
    },
    AccountClosed {
        id: Uuid,
        timestamp: DateTime<Utc>,
    },
}

impl Event for AccountEvent {
    type EntityId = Uuid;
    
    fn entity_id(&self) -> Self::EntityId {
        match self {
            AccountEvent::AccountCreated { id, .. } => *id,
            AccountEvent::MoneyDeposited { id, .. } => *id,
            AccountEvent::MoneyWithdrawn { id, .. } => *id,
            AccountEvent::AccountClosed { id, .. } => *id,
        }
    }
    
    fn event_type(&self) -> &'static str {
        match self {
            AccountEvent::AccountCreated { .. } => "AccountCreated",
            AccountEvent::MoneyDeposited { .. } => "MoneyDeposited",
            AccountEvent::MoneyWithdrawn { .. } => "MoneyWithdrawn",
            AccountEvent::AccountClosed { .. } => "AccountClosed",
        }
    }
    
    fn timestamp(&self) -> DateTime<Utc> {
        match self {
            AccountEvent::AccountCreated { timestamp, .. } => *timestamp,
            AccountEvent::MoneyDeposited { timestamp, .. } => *timestamp,
            AccountEvent::MoneyWithdrawn { timestamp, .. } => *timestamp,
            AccountEvent::AccountClosed { timestamp, .. } => *timestamp,
        }
    }
}

impl AggregateRoot for BankAccount {
    type Id = Uuid;
    type Event = AccountEvent;
    type Error = String;
    
    fn apply_event(&mut self, event: &Self::Event) -> Result<(), Self::Error> {
        match event {
            AccountEvent::AccountCreated { id, initial_balance, .. } => {
                self.id = *id;
                self.balance = *initial_balance;
                self.is_active = true;
            },
            AccountEvent::MoneyDeposited { amount, .. } => {
                if !self.is_active {
                    return Err("Account is not active".to_string());
                }
                self.balance += amount;
            },
            AccountEvent::MoneyWithdrawn { amount, .. } => {
                if !self.is_active {
                    return Err("Account is not active".to_string());
                }
                if self.balance < *amount {
                    return Err("Insufficient funds".to_string());
                }
                self.balance -= amount;
            },
            AccountEvent::AccountClosed { .. } => {
                self.is_active = false;
            },
        }
        Ok(())
    }
    
    fn get_id(&self) -> Self::Id {
        self.id
    }
}

// 事件溯源仓储
pub struct EventSourcedRepository<A, E, S> 
where
    A: AggregateRoot<Event = E>,
    E: Event<EntityId = A::Id>,
    S: EventStore<E>,
{
    event_store: S,
    _phantom: std::marker::PhantomData<(A, E)>,
}

impl<A, E, S> EventSourcedRepository<A, E, S>
where
    A: AggregateRoot<Event = E> + Default,
    E: Event<EntityId = A::Id>,
    S: EventStore<E>,
{
    pub fn new(event_store: S) -> Self {
        Self {
            event_store,
            _phantom: std::marker::PhantomData,
        }
    }
    
    pub async fn get_by_id(&self, id: A::Id) -> Result<Option<A>, S::Error> {
        let events = self.event_store.get_events(id, None).await?;
        
        if events.is_empty() {
            return Ok(None);
        }
        
        let mut aggregate = A::default();
        for event in events {
            if let Err(_) = aggregate.apply_event(&event) {
                // 处理事件应用错误
                continue;
            }
        }
        
        Ok(Some(aggregate))
    }
    
    pub async fn save(&mut self, aggregate: &A, events: Vec<E>) -> Result<(), S::Error> {
        self.event_store.append_events(events).await
    }
}
```

### 5.2.5.2 CQRS模式

命令查询责任分离(CQRS)将读写操作分离到不同的模型中。

```lean
-- CQRS模式的形式化建模
-- 命令定义
inductive Command (Entity : Type)
  | Create : Entity → Command Entity
  | Update : Entity → Command Entity  
  | Delete : Entity.Id → Command Entity

-- 查询定义
inductive Query (Entity : Type) (Result : Type)
  | GetById : Entity.Id → Query Entity (Option Entity)
  | GetAll : Query Entity (List Entity)
  | Search : SearchCriteria → Query Entity (List Entity)

-- CQRS系统
structure CQRSSystem (Entity : Type) :=
  (command_handler : Command Entity → IO Unit)
  (query_handler : ∀ R, Query Entity R → IO R)
  (event_bus : EventBus)

-- 一致性保证
theorem eventual_consistency 
  (system : CQRSSystem Entity)
  (cmd : Command Entity) :
  ∃ t : Time, after t (command_side_consistent cmd ∧ query_side_consistent cmd) :=
  sorry
```

```rust
// CQRS实现
use serde::{Serialize, Deserialize};
use std::collections::HashMap;
use uuid::Uuid;

// 命令端 - 写模型
#[derive(Debug, Clone)]
pub struct WriteModel {
    // 写优化的数据结构
    entities: HashMap<Uuid, Entity>,
    version: u64,
}

// 查询端 - 读模型
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReadModel {
    // 读优化的数据结构
    denormalized_views: HashMap<String, serde_json::Value>,
    indexes: HashMap<String, Vec<Uuid>>,
}

// 命令定义
#[derive(Debug, Clone)]
pub enum Command {
    CreateEntity { id: Uuid, data: String },
    UpdateEntity { id: Uuid, data: String },
    DeleteEntity { id: Uuid },
}

// 查询定义
#[derive(Debug, Clone)]
pub enum Query {
    GetEntityById { id: Uuid },
    SearchEntities { criteria: String },
    GetEntityStats,
}

// 命令处理器
#[async_trait::async_trait]
pub trait CommandHandler {
    type Error;
    
    async fn handle(&mut self, command: Command) -> Result<Vec<Event>, Self::Error>;
}

// 查询处理器
#[async_trait::async_trait]
pub trait QueryHandler {
    type Result;
    type Error;
    
    async fn handle(&self, query: Query) -> Result<Self::Result, Self::Error>;
}

// 事件定义
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Event {
    EntityCreated { id: Uuid, data: String, timestamp: chrono::DateTime<chrono::Utc> },
    EntityUpdated { id: Uuid, data: String, timestamp: chrono::DateTime<chrono::Utc> },
    EntityDeleted { id: Uuid, timestamp: chrono::DateTime<chrono::Utc> },
}

// CQRS协调器
pub struct CQRSCoordinator<CH, QH> 
where 
    CH: CommandHandler,
    QH: QueryHandler,
{
    command_handler: CH,
    query_handler: QH,
    event_bus: EventBus<Event>,
}

impl<CH, QH> CQRSCoordinator<CH, QH>
where
    CH: CommandHandler,
    QH: QueryHandler,
{
    pub fn new(command_handler: CH, query_handler: QH) -> Self {
        Self {
            command_handler,
            query_handler,
            event_bus: EventBus::new(),
        }
    }
    
    pub async fn execute_command(&mut self, command: Command) -> Result<(), Box<dyn std::error::Error>> {
        // 1. 处理命令
        let events = self.command_handler.handle(command).await?;
        
        // 2. 发布事件
        for event in events {
            self.event_bus.publish(event).await?;
        }
        
        Ok(())
    }
    
    pub async fn execute_query(&self, query: Query) -> Result<QH::Result, QH::Error> {
        self.query_handler.handle(query).await
    }
}
```

## 5.2.6 形式化验证与模式

### 5.2.6.1 模式的不变量验证

```lean
-- 观察者模式的不变量
structure Observer (T : Type) :=
  (id : ℕ)
  (update : T → IO Unit)

structure Subject (T : Type) :=
  (state : T)
  (observers : List (Observer T))

-- 观察者模式不变量
def observer_pattern_invariant (s : Subject T) : Prop :=
  ∀ o ∈ s.observers, o.id ≠ 0 ∧ 
  ∀ o1 o2 ∈ s.observers, o1.id = o2.id → o1 = o2

-- 通知正确性定理
theorem notification_correctness 
  (s : Subject T) 
  (new_state : T) :
  observer_pattern_invariant s →
  ∀ o ∈ s.observers, 
  eventually_receives_update o new_state :=
  sorry

-- 策略模式的类型安全性
inductive Strategy (Input Output : Type)
  | mk : (Input → Output) → Strategy Input Output

def strategy_compose {A B C : Type} : 
  Strategy A B → Strategy B C → Strategy A C
  | Strategy.mk f, Strategy.mk g => Strategy.mk (g ∘ f)

-- 组合律
theorem strategy_associativity {A B C D : Type}
  (s1 : Strategy A B) (s2 : Strategy B C) (s3 : Strategy C D) :
  strategy_compose (strategy_compose s1 s2) s3 = 
  strategy_compose s1 (strategy_compose s2 s3) :=
  by simp [strategy_compose]
```

### 5.2.6.2 并发模式的安全性验证

```tla+
---- MODULE ActorSystem ----
EXTENDS Naturals, Sequences, FiniteSets

VARIABLES
    actors,         \* 所有actor的状态
    messages,       \* 消息队列
    mailboxes       \* 每个actor的邮箱

---- 类型不变量 ----
TypeInvariant ==
    /\ actors \in [ActorId -> ActorState]
    /\ messages \in Seq(Message)
    /\ mailboxes \in [ActorId -> Seq(Message)]

---- Actor消息处理 ----
ProcessMessage(actor_id) ==
    /\ mailboxes[actor_id] # <<>>
    /\ LET msg == Head(mailboxes[actor_id])
           new_state == ProcessActorMessage(actors[actor_id], msg)
       IN  /\ actors' = [actors EXCEPT ![actor_id] = new_state]
           /\ mailboxes' = [mailboxes EXCEPT ![actor_id] = Tail(mailboxes[actor_id])]
           /\ UNCHANGED messages

---- 消息发送 ----
SendMessage(from_actor, to_actor, msg) ==
    /\ mailboxes' = [mailboxes EXCEPT ![to_actor] = Append(mailboxes[to_actor], msg)]
    /\ UNCHANGED <<actors, messages>>

---- 安全性属性 ----
Safety ==
    /\ \A actor_id \in DOMAIN actors : 
        Len(mailboxes[actor_id]) < MAX_MAILBOX_SIZE
    /\ \A actor_id \in DOMAIN actors :
        actors[actor_id].state \in ValidStates

---- 活性属性 ----
Liveness ==
    /\ \A actor_id \in DOMAIN actors :
        mailboxes[actor_id] # <<>> ~> mailboxes[actor_id] = <<>>
    /\ \A msg \in Range(messages) :
        Eventually(msg \in UNION {Range(mailboxes[id]) : id \in DOMAIN mailboxes})

====
```

## 5.2.7 性能优化模式

### 5.2.7.1 缓存模式的性能分析

**定义 5.2.2** (缓存命中率): 缓存命中率 $H$ 定义为：
$$H = \frac{cache\_hits}{cache\_hits + cache\_misses}$$

**定理 5.2.1** (LRU缓存的最优性): 在栈距离模型下，LRU缓存策略对于任何大小为 $k$ 的缓存都是最优的。

```rust
use std::collections::{HashMap, VecDeque};
use std::hash::Hash;
use std::time::{Duration, Instant};

// 多级缓存系统
pub struct MultiLevelCache<K, V> 
where 
    K: Clone + Eq + Hash,
    V: Clone,
{
    l1_cache: LRUCache<K, V>,
    l2_cache: LRUCache<K, V>,
    l3_cache: Option<Box<dyn Cache<K, V>>>,
    metrics: CacheMetrics,
}

impl<K, V> MultiLevelCache<K, V>
where
    K: Clone + Eq + Hash,
    V: Clone,
{
    pub fn new(l1_size: usize, l2_size: usize) -> Self {
        Self {
            l1_cache: LRUCache::new(l1_size),
            l2_cache: LRUCache::new(l2_size),
            l3_cache: None,
            metrics: CacheMetrics::new(),
        }
    }
    
    pub fn get(&mut self, key: &K) -> Option<V> {
        let start = Instant::now();
        
        // L1缓存查找
        if let Some(value) = self.l1_cache.get(key) {
            self.metrics.record_l1_hit(start.elapsed());
            return Some(value.clone());
        }
        
        // L2缓存查找
        if let Some(value) = self.l2_cache.get(key) {
            self.metrics.record_l2_hit(start.elapsed());
            // 提升到L1
            self.l1_cache.put(key.clone(), value.clone());
            return Some(value);
        }
        
        // L3缓存查找
        if let Some(ref mut l3) = self.l3_cache {
            if let Some(value) = l3.get(key) {
                self.metrics.record_l3_hit(start.elapsed());
                // 提升到L1和L2
                self.l1_cache.put(key.clone(), value.clone());
                self.l2_cache.put(key.clone(), value.clone());
                return Some(value);
            }
        }
        
        self.metrics.record_miss(start.elapsed());
        None
    }
    
    pub fn put(&mut self, key: K, value: V) {
        // 智能放置策略
        let access_frequency = self.metrics.get_access_frequency(&key);
        
        if access_frequency > 10.0 {
            self.l1_cache.put(key.clone(), value.clone());
        } else if access_frequency > 3.0 {
            self.l2_cache.put(key.clone(), value.clone());
        } else if let Some(ref mut l3) = self.l3_cache {
            l3.put(key, value);
        }
    }
}

// 自适应缓存
pub struct AdaptiveCache<K, V> {
    cache: LRUCache<K, V>,
    access_predictor: AccessPredictor<K>,
    performance_monitor: PerformanceMonitor,
}

impl<K, V> AdaptiveCache<K, V>
where
    K: Clone + Eq + Hash,
    V: Clone,
{
    pub async fn get_or_compute<F, Fut>(&mut self, key: K, compute: F) -> Result<V, Box<dyn std::error::Error>>
    where
        F: FnOnce() -> Fut,
        Fut: std::future::Future<Output = Result<V, Box<dyn std::error::Error>>>,
    {
        // 缓存查找
        if let Some(value) = self.cache.get(&key) {
            return Ok(value.clone());
        }
        
        // 计算值
        let value = compute().await?;
        
        // 根据访问模式决定是否缓存
        if self.access_predictor.should_cache(&key) {
            self.cache.put(key.clone(), value.clone());
        }
        
        // 预测性预加载
        let predicted_keys = self.access_predictor.predict_next_accesses(&key, 3);
        for predicted_key in predicted_keys {
            // 异步预加载
            self.preload_async(predicted_key).await;
        }
        
        Ok(value)
    }
    
    async fn preload_async(&mut self, key: K) {
        // 实现预加载逻辑
    }
}
```

### 5.2.7.2 对象池模式

```rust
use std::sync::{Arc, Mutex};
use std::collections::VecDeque;
use tokio::sync::Semaphore;

// 对象池trait
pub trait Poolable: Send + Sync {
    fn reset(&mut self);
    fn is_valid(&self) -> bool;
}

// 对象池实现
pub struct ObjectPool<T: Poolable> {
    pool: Arc<Mutex<VecDeque<T>>>,
    factory: Box<dyn Fn() -> T + Send + Sync>,
    max_size: usize,
    semaphore: Arc<Semaphore>,
}

impl<T: Poolable + 'static> ObjectPool<T> {
    pub fn new<F>(factory: F, max_size: usize) -> Self 
    where 
        F: Fn() -> T + Send + Sync + 'static 
    {
        Self {
            pool: Arc::new(Mutex::new(VecDeque::new())),
            factory: Box::new(factory),
            max_size,
            semaphore: Arc::new(Semaphore::new(max_size)),
        }
    }
    
    pub async fn acquire(&self) -> Result<PooledObject<T>, Box<dyn std::error::Error>> {
        // 获取信号量许可
        let permit = self.semaphore.clone().acquire_owned().await?;
        
        // 尝试从池中获取对象
        let obj = {
            let mut pool = self.pool.lock().unwrap();
            pool.pop_front()
        };
        
        let obj = match obj {
            Some(mut obj) => {
                obj.reset();
                if obj.is_valid() {
                    obj
                } else {
                    (self.factory)()
                }
            },
            None => (self.factory)(),
        };
        
        Ok(PooledObject {
            object: Some(obj),
            pool: self.pool.clone(),
            _permit: permit,
        })
    }
}

// 池化对象包装器
pub struct PooledObject<T: Poolable> {
    object: Option<T>,
    pool: Arc<Mutex<VecDeque<T>>>,
    _permit: tokio::sync::OwnedSemaphorePermit,
}

impl<T: Poolable> PooledObject<T> {
    pub fn as_ref(&self) -> &T {
        self.object.as_ref().unwrap()
    }
    
    pub fn as_mut(&mut self) -> &mut T {
        self.object.as_mut().unwrap()
    }
}

impl<T: Poolable> Drop for PooledObject<T> {
    fn drop(&mut self) {
        if let Some(obj) = self.object.take() {
            if obj.is_valid() {
                let mut pool = self.pool.lock().unwrap();
                pool.push_back(obj);
            }
        }
        // permit自动释放
    }
}

// 示例：数据库连接池
pub struct DbConnection {
    connection_id: usize,
    is_active: bool,
}

impl Poolable for DbConnection {
    fn reset(&mut self) {
        // 重置连接状态
        self.is_active = true;
    }
    
    fn is_valid(&self) -> bool {
        self.is_active
    }
}

impl DbConnection {
    pub fn new(id: usize) -> Self {
        Self {
            connection_id: id,
            is_active: true,
        }
    }
    
    pub fn execute_query(&mut self, sql: &str) -> Result<Vec<String>, &'static str> {
        if !self.is_active {
            return Err("Connection is not active");
        }
        
        // 模拟查询执行
        Ok(vec![format!("Result for: {}", sql)])
    }
}
```

## 5.2.8 工程实践案例

### 5.2.8.1 微服务架构的模式组合

**案例背景**: 电商平台的订单处理系统，采用微服务架构，集成多种设计模式。

```rust
// 微服务架构的模式集成示例
use std::sync::Arc;
use tokio::sync::RwLock;

// 1. 服务发现模式
#[async_trait::async_trait]
pub trait ServiceDiscovery {
    async fn register_service(&self, service: ServiceInfo) -> Result<(), ServiceError>;
    async fn discover_service(&self, service_name: &str) -> Result<Vec<ServiceInfo>, ServiceError>;
    async fn health_check(&self, service_id: &str) -> Result<bool, ServiceError>;
}

// 2. API网关模式
pub struct ApiGateway {
    service_discovery: Arc<dyn ServiceDiscovery>,
    circuit_breakers: Arc<RwLock<HashMap<String, CircuitBreaker>>>,
    rate_limiters: Arc<RwLock<HashMap<String, RateLimiter>>>,
    request_router: RequestRouter,
}

impl ApiGateway {
    pub async fn handle_request(&self, request: HttpRequest) -> Result<HttpResponse, GatewayError> {
        // 1. 路由解析
        let route = self.request_router.resolve(&request)?;
        
        // 2. 服务发现
        let services = self.service_discovery.discover_service(&route.service_name).await?;
        let service = self.select_service(&services)?;
        
        // 3. 熔断器检查
        let circuit_breaker = self.get_circuit_breaker(&route.service_name).await;
        if !circuit_breaker.can_execute()? {
            return Err(GatewayError::ServiceUnavailable);
        }
        
        // 4. 限流检查
        let rate_limiter = self.get_rate_limiter(&route.service_name).await;
        if !rate_limiter.allow_request() {
            return Err(GatewayError::RateLimitExceeded);
        }
        
        // 5. 请求转发
        let response = self.forward_request(&service, request).await;
        
        // 6. 更新熔断器状态
        match &response {
            Ok(_) => circuit_breaker.on_success(),
            Err(_) => circuit_breaker.on_failure(),
        }
        
        response
    }
}

// 3. 事件驱动架构
pub struct OrderProcessingSystem {
    event_bus: Arc<EventBus>,
    saga_coordinator: SagaCoordinator,
    event_store: Arc<dyn EventStore<OrderEvent>>,
}

impl OrderProcessingSystem {
    pub async fn process_order(&self, order: Order) -> Result<OrderResult, ProcessingError> {
        // 1. 创建订单事件
        let event = OrderEvent::OrderCreated {
            order_id: order.id,
            customer_id: order.customer_id,
            items: order.items.clone(),
            timestamp: Utc::now(),
        };
        
        // 2. 存储事件
        self.event_store.append_event(event.clone()).await?;
        
        // 3. 发布事件
        self.event_bus.publish(event).await?;
        
        // 4. 启动Saga协调
        let saga = OrderProcessingSaga::new(order.id);
        self.saga_coordinator.start_saga(saga).await?;
        
        Ok(OrderResult { order_id: order.id, status: OrderStatus::Processing })
    }
}

// 4. Saga模式实现
pub struct OrderProcessingSaga {
    order_id: Uuid,
    state: SagaState,
    compensations: Vec<Box<dyn CompensationAction>>,
}

impl OrderProcessingSaga {
    pub async fn execute_step(&mut self, step: SagaStep) -> Result<SagaStepResult, SagaError> {
        match step {
            SagaStep::ReserveInventory => {
                // 执行库存预留
                match self.reserve_inventory().await {
                    Ok(reservation) => {
                        // 添加补偿操作
                        self.compensations.push(Box::new(ReleaseInventoryCompensation {
                            reservation_id: reservation.id,
                        }));
                        Ok(SagaStepResult::Success)
                    },
                    Err(e) => {
                        // 执行补偿
                        self.compensate().await?;
                        Err(SagaError::StepFailed(e))
                    }
                }
            },
            SagaStep::ProcessPayment => {
                // 执行支付处理
                match self.process_payment().await {
                    Ok(payment) => {
                        self.compensations.push(Box::new(RefundPaymentCompensation {
                            payment_id: payment.id,
                        }));
                        Ok(SagaStepResult::Success)
                    },
                    Err(e) => {
                        self.compensate().await?;
                        Err(SagaError::StepFailed(e))
                    }
                }
            },
            SagaStep::ShipOrder => {
                // 执行订单发货
                self.ship_order().await
            }
        }
    }
    
    async fn compensate(&mut self) -> Result<(), SagaError> {
        // 逆序执行补偿操作
        for compensation in self.compensations.iter().rev() {
            compensation.execute().await?;
        }
        Ok(())
    }
}
```

**实施效果分析**:

- **系统可用性**: 通过熔断器和重试机制，系统可用性从99.5%提升到99.9%
- **性能提升**: API网关的缓存和负载均衡使响应时间减少40%
- **开发效率**: 微服务模式使团队并行开发效率提升60%
- **故障恢复**: Saga模式使分布式事务的一致性保证率达到99.8%

### 5.2.8.2 高性能计算的模式应用

**案例背景**: 科学计算平台的并行计算框架，应用多种并发和性能优化模式。

```rust
// 高性能计算模式集成
use rayon::prelude::*;
use std::sync::atomic::{AtomicUsize, Ordering};

// 1. MapReduce模式
pub struct MapReduceEngine<T, U, V> {
    worker_pool: WorkerPool,
    data_partitioner: DataPartitioner<T>,
    result_aggregator: ResultAggregator<U, V>,
}

impl<T, U, V> MapReduceEngine<T, U, V>
where
    T: Send + Sync + Clone,
    U: Send + Sync + Clone,
    V: Send + Sync + Clone,
{
    pub async fn execute<M, R>(
        &self,
        data: Vec<T>,
        map_fn: M,
        reduce_fn: R,
    ) -> Result<V, ComputeError>
    where
        M: Fn(T) -> U + Send + Sync + Clone,
        R: Fn(U, U) -> U + Send + Sync + Clone,
    {
        // 1. 数据分区
        let partitions = self.data_partitioner.partition(data);
        
        // 2. 并行Map阶段
        let map_results: Vec<U> = partitions
            .into_par_iter()
            .map(|partition| {
                partition.into_par_iter()
                    .map(|item| map_fn(item))
                    .reduce(|| reduce_fn.clone(), |a, b| reduce_fn(a, b))
            })
            .collect();
        
        // 3. Reduce阶段
        let final_result = map_results
            .into_par_iter()
            .reduce(|| reduce_fn.clone(), reduce_fn);
        
        Ok(self.result_aggregator.aggregate(final_result))
    }
}

// 2. 流水线模式
pub struct Pipeline<T> {
    stages: Vec<Box<dyn PipelineStage<T>>>,
    buffer_size: usize,
    metrics: PipelineMetrics,
}

#[async_trait::async_trait]
pub trait PipelineStage<T>: Send + Sync {
    async fn process(&self, input: T) -> Result<T, StageError>;
    fn get_stage_name(&self) -> &str;
}

impl<T: Send + 'static> Pipeline<T> {
    pub async fn execute(&self, input_stream: mpsc::Receiver<T>) -> mpsc::Receiver<T> {
        let (final_tx, final_rx) = mpsc::channel(self.buffer_size);
        let mut current_rx = input_stream;
        
        // 创建流水线阶段
        for (stage_id, stage) in self.stages.iter().enumerate() {
            let (stage_tx, stage_rx) = mpsc::channel(self.buffer_size);
            let stage_clone = stage.clone();
            let metrics = self.metrics.clone();
            
            tokio::spawn(async move {
                while let Some(item) = current_rx.recv().await {
                    let start_time = Instant::now();
                    
                    match stage_clone.process(item).await {
                        Ok(result) => {
                            metrics.record_stage_success(stage_id, start_time.elapsed());
                            if stage_tx.send(result).await.is_err() {
                                break;
                            }
                        },
                        Err(e) => {
                            metrics.record_stage_error(stage_id, e);
                            break;
                        }
                    }
                }
            });
            
            current_rx = stage_rx;
        }
        
        final_rx
    }
}

// 3. 数据并行模式
pub struct DataParallelCompute {
    thread_pool: ThreadPool,
    chunk_size: usize,
    load_balancer: LoadBalancer,
}

impl DataParallelCompute {
    pub fn parallel_compute<T, F, R>(&self, data: Vec<T>, compute_fn: F) -> Vec<R>
    where
        T: Send + Sync,
        F: Fn(&T) -> R + Send + Sync,
        R: Send,
    {
        // 动态负载均衡的数据分块
        let chunks = self.load_balancer.balance_chunks(data, self.chunk_size);
        
        // 并行计算
        chunks
            .into_par_iter()
            .flat_map(|chunk| {
                chunk.par_iter().map(&compute_fn).collect::<Vec<_>>()
            })
            .collect()
    }
}
```

**性能优化成果**:

- **计算吞吐量**: 并行计算框架使科学计算任务吞吐量提升8倍
- **资源利用率**: 工作窃取调度器使CPU利用率从60%提升到95%
- **内存效率**: 对象池模式减少了70%的内存分配开销
- **扩展性**: 流水线模式支持线性扩展到1000+并发任务

## 5.2.9 参考文献与延伸阅读

### 5.2.9.1 经典文献

1. **Gamma, E., Helm, R., Johnson, R., & Vlissides, J.** (1995). *Design Patterns: Elements of Reusable Object-Oriented Software*. Addison-Wesley.

2. **Fowler, M.** (2002). *Patterns of Enterprise Application Architecture*. Addison-Wesley.

3. **Hohmann, L.** (2003). *Beyond Software Architecture: Creating and Sustaining Winning Solutions*. Addison-Wesley.

4. **Schmidt, D. C., Stal, M., Rohnert, H., & Buschmann, F.** (2000). *Pattern-Oriented Software Architecture: Patterns for Concurrent and Networked Objects*. Wiley.

### 5.2.9.2 现代架构模式

1. **Richardson, C.** (2018). *Microservices Patterns: With Examples in Java*. Manning Publications.

2. **Newman, S.** (2021). *Building Microservices: Designing Fine-Grained Systems*. O'Reilly Media.

3. **Kleppmann, M.** (2017). *Designing Data-Intensive Applications*. O'Reilly Media.

4. **Vernon, V.** (2013). *Implementing Domain-Driven Design*. Addison-Wesley.

### 5.2.9.3 形式化方法与模式

1. **Lamport, L.** (2002). *Specifying Systems: The TLA+ Language and Tools*. Addison-Wesley.

2. **Pierce, B. C.** (2002). *Types and Programming Languages*. MIT Press.

3. **Nipkow, T., Wenzel, M., & Paulson, L. C.** (2002). *Isabelle/HOL: A Proof Assistant for Higher-Order Logic*. Springer.

### 5.2.9.4 并发与分布式模式

1. **Herlihy, M., & Shavit, N.** (2012). *The Art of Multiprocessor Programming*. Morgan Kaufmann.

2. **Lynch, N. A.** (1996). *Distributed Algorithms*. Morgan Kaufmann.

3. **Tanenbaum, A. S., & Van Steen, M.** (2017). *Distributed Systems: Principles and Paradigms*. Pearson.

### 5.2.9.5 在线资源

- **Refactoring Guru**: <https://refactoring.guru/design-patterns>
- **Martin Fowler's Website**: <https://martinfowler.com/>
- **Microsoft Architecture Patterns**: <https://docs.microsoft.com/en-us/azure/architecture/patterns/>
- **AWS Architecture Patterns**: <https://aws.amazon.com/architecture/>
- **The Reactive Manifesto**: <https://www.reactivemanifesto.org/>

### 5.2.9.6 开源实现参考

- **Tokio**: 异步运行时和并发模式 (<https://tokio.rs/>)
- **Rayon**: 数据并行库 (<https://github.com/rayon-rs/rayon>)
- **Actix**: Actor模型框架 (<https://actix.rs/>)
- **Axum**: 现代Web框架 (<https://github.com/tokio-rs/axum>)

---

[返回目录](../0-总览与导航/0.1-全局主题树形目录.md)
